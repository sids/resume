\documentclass{resume}
\usepackage{url}
\usepackage[pdfborderstyle={/W 0}]{hyperref}

%
\renewcommand{\labelitemi}{$\diamond$}
\newcommand{\teamsize}{\hfill\sc\footnotesize Team Size: }


\author{Siddhartha Reddy Kothakapu}


% - Address --------------------------------------------------------
\address {
    \url{http://www.grok.in/}\\
    \url{http://www.linkedin.com/in/sidsr}
}
{
    \href{mailto:sids@grok.in}{sids@grok.in}\\
    +91 998 028 7437
}


\begin{document} \maketitle

% - Education ---------------------------------------------------
\begin{category}{Education}{}

    \item {\topic M.Tech in Information Technology}
        {\footnotesize(3.71/4 CGPA)}
        {\period Jun 2006}
        \begin{quote}
            International Institute of Information Technology, Bangalore
        \end{quote}

\end{category}


% - Experience --------------------------------------------------
\begin{category}{Experience}{}

    \item {\topic Senior/ Software Engineer,} Ziva Software Pvt. Ltd., Bangalore
        {\period Jul 2006 - Dec 2008}
        \begin{quote}
            \href{http://www.zook.in/}{{\hl Ziva Software}} is a Venture
            Capital funded startup based out of Bangalore, providing products
            and services in the {\hl Mobile Search} domain.  Established in
            late 2005, Ziva has provided search solutions to different players
            in the mobile industry including several operators and content
            owners. In 2007, Ziva launched \href{http://www.zook.in/}{{\hl
            Zook}}, it's consumer facing mobile search system.
        \end{quote}
        \begin{quote}
            Was the first non-founding employee to join the company. Have been
            a core member of the team, involved in most of the projects, and    % TODO: comma before 'and' appropriate?
            actively participated in defining the development roadmap for them.
            % TODO: ``for them'' or ``for the company''?
        \end{quote}

\end{category}


% - Intersts --------------------------------------------------
\begin{category}{Interests}{}

    \item Information Engineering---Retrieval, Extraction \&
    Management, Scalable Architectures, Distributed \& Cloud Computing,
    Usability \& User Experience

\end{category}


% - Skills --------------------------------------------------
\begin{category}{Skills}{}

    \item {\topic Languages:} Perl, Java, PHP, Ruby, Javascript, C/C++, C{\tt \#}
        %, Python

    \item {\topic Frameworks/Libraries:} Hadoop, Nutch, Lucene, Solr, Sphinx,
        WEKA, Ruby on Rails, Prototype
        %, jQuery, Hibernate

    \item {\topic Others:} HTML, CSS, JSP, Bash Shell Scripting

\end{category}


% - Projects ---------------------------------------------------
\begin{category}{Selected Projects}{}

    \item {\topic Buddhi Online,} Ziva Software
        {\teamsize 1}
        {\period Nov 2007 - Present}
        \begin{quote}
            A system to fetch {\hl Yahoo! BOSS} Web search results in response
            to a user query, fetch the result web pages and extract {\hl
            snippets} that can possibly provide an answer to the query right
            away.
        \end{quote}
        \begin{quote}
            Developed a prototype of the system as part of a feasibility
            analysis. Working on building out the complete system in order to
            deploy it in production.
        \end{quote}

    \item {\topic Buddhi,} Ziva Software
        {\teamsize 2-3}
        {\period Apr 2007 - Present}
        \begin{quote}
            A dream to crawl the Web and automagically extract {\hl information
            content entities} off the crawled pages.
        \end{quote}
        \begin{quote}
            \begin{itemize}
                \item Designed the {\hl Map-Reduce} based architecture for the
                    system.
                \item Implemented a {\hl focused crawler} based on the {\hl
                    Nutch} open source crawler. The crawler has been deployed
                    and regularly crawls major portions of the Web.
                \item Introduced the concept of---and implemented---a {\hl
                    HTML reducer} that transforms complex HTML pages into
                    minimal HTML for easier analysis. This is the first step of
                    the analysis performed by the system.
                \item Defined a {\hl page abstractor} as a component that
                    discerns logical structures from unstructured HTML.
                    Implemented a {\hl table abstractor} that identifies
                    tabular structure in web pages---even when the HTML does
                    not contain any tables per se.
                \item Set up the {\hl Hadoop} based infrastructure for the
                    crawling and extraction. Initially set it up on a cluster
                    of {\hl Amazon EC2} machines with {\hl Amazon S3} as a data
                    store. Later moved it to a set of dedicated machines.
            \end{itemize}
        \end{quote}

    \pagebreak

    \item {\topic Zook,} Ziva Software
        {\teamsize 2-3}
        {\period Jan 2007 - Present}
        \begin{quote}
            Ziva Software's flagship mobile search engine. The main promise is
            to provide exact answers to questions in the least number of
            clicks; implying that the search engine provides information right
            away rather than directing the user to another website that {\hl
            might} have the information.
        \end{quote}
        \begin{quote}
            \begin{itemize}
                \item Set up the search system infrastructure.
                \item Designed the {\hl User Experience} and {\hl User
                    Interface} of the WAP and SMS interfaces.
                \item Responsible for deploying releases.
                \item Created a HTTP based API for accessing the search system.
            \end{itemize}
        \end{quote}

    \item {\topic Zivabot,} Ziva Software
        {\teamsize 1}
        {\period Aug 2006 - Oct 2006}
        \begin{quote}
            A {\hl scalable, highly-configurable, generic scraping system} for
            crawling specific websites containing useful information and then
            extracting that information.
        \end{quote}
        \begin{quote}
            Was fully responsible for the design and implementation of the
            system. Configured the system and set it up to work with an initial
            set of websites; this provided the base content for the Zook mobile
            search engine.
        \end{quote}

    \item {\topic Better Web Buys}
        {\teamsize 2}
        {\period Feb 2006 - May 2006}
        \begin{quote}
            A {\hl faceted price comparison shopping search engine} with over
            20 million items across more than 100 merchants.
        \end{quote}
        \begin{quote}
            Was completely responsible for the whole project right from
            fetching the product feeds, parsing and storing them in a database,
            indexing, searching, user experience and setting up the entire
            system on a cluster of machines. Used {\hl Sphinx} as the backend
            full-text indexing system.
        \end{quote}

    \item {\topic yadb -- Yet Another DataBase,} IIIT, Bangalore
        {\teamsize 3}
        {\period Aug 2005 - Dec 2005}
        \begin{quote}
            A reasonably {\hl complete RDBMS} with a buffered memory manager,
            B+ tree indexing and a complete database management module
            including support for basic SQL, table management, paged storage
            etc. Part of the {\hl Advanced Databases} course.
        \end{quote}

    \item {\topic Top News,} IIIT, Bangalore
        {\teamsize 1}
        {\period Sep 2005 - Oct 2005}
        \begin{quote}
            A system to bring out the top news of the hour by {\hl clustering
            the news items} obtained from the feeds provided by several news
            sources. Any news being discussed by multiple sources within a
            given (variable) timeframe is marked as top news. A bi-partite
            graph based clustering algorithm was used for clustering based on
            just the title and summary of the news item. Project for the {\hl
            Web Information Retreival} course.
        \end{quote}

    \item {\topic SiDuSE,} IIIT, Bangalore
        {\teamsize 2}
        {\period Aug 2004 - Sep 2004}
        \begin{quote}
            A {\hl Simple Desktop Search Engine} for Linux/UNIX systems.
            Creates a Trie-based full-text index of the files on the system.
            Apart from allowing the basic $AND$, $OR$ \& $NOT$ operators, the
            system supports complex querying through nested queries, phrase
            matching and prefix queries. Part of the {\hl Mathematical
            Foundations of Computing} course.
        \end{quote}

    \item {\topic SOS -- S Operating System}
        {\teamsize 2}
        {\period Sep 2002 - Oct 2003}
        \begin{quote}
            A simple monolithic kernel with kernel level threads, kernel level
            IPC and advanced memory management.
        \end{quote}

\end{category}


% -Publications ------------------------------------------ %
\begin{category}{Publication}{}

    \item {\topic Measures of ``Ignorance'' on the Web}
        {\period Dec 2006}
        \begin{quote}
            International Conference on Management of Data, Delhi, India
        \end{quote}

\end{category}


% - Honors ---------------------------------------------------
\begin{category}{Honors}{$\diamond$}

    \item {\hl Valedictorian} for the class for 2006 at IIIT, Bangalore.
    %{\period Jun 2006}

    \item Was awarded the {\hl Honeywell Scholarship} for academic excellence
        at IIIT, Bangalore.
    %{\period Jun 2006}

    \item Was chosen as the {\hl employee of the year} for 2007-08 at Ziva
        Software.

\end{category}


\end{document}
